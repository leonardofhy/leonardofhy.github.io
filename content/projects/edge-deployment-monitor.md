---
title: "Edge Deployment Monitor"
date: 2026-02-08
draft: false
summary: "A small dashboard concept to track model inference latency, error rates, and release rollbacks across edge nodes."
tags: ["MLOps", "Monitoring", "Edge AI"]
categories: ["Projects"]
technologies:
  - "Python"
  - "FastAPI"
  - "Prometheus"
  - "Docker"
featured: true
project_url: "https://github.com/leonardofhy"
---

A compact monitoring utility that collects telemetry from distributed inference services and makes issues easy to spot.

## Highlights

- Lightweight instrumentation with minimal overhead.
- Clear signal cards for inference speed and stability.
- Easy extension points for new metrics.

## Outcome

- Improved detection time for latency spikes and failures.
- Clearer feedback loop during model updates.
